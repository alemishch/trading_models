{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "213a5c1b-829e-49f3-b59f-2ac9d9e50608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e5d01ff-9e6a-40bb-bd4e-b5a4cfa36180",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_features_dir = \"\"\n",
    "returns_features_dir = \"returns_features/\" \n",
    "merged_features_dir = \"merged_data/\"           \n",
    "models_dir = \"models/\"                          \n",
    "evaluations_dir = \"evaluations/\" \n",
    "tickers = [\"BTCUSDT\"]\n",
    "\n",
    "for directory in [merged_features_dir, models_dir, evaluations_dir]:\n",
    "        os.makedirs(directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b07230aa-6bd0-405c-a019-e0a188747975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(filepath):\n",
    "    try:\n",
    "        df = pd.read_csv(\n",
    "            filepath,\n",
    "            index_col=0,\n",
    "            parse_dates=[0],\n",
    "            low_memory=False\n",
    "        )\n",
    "        df.sort_index(inplace=True)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"{e}\")\n",
    "        return None\n",
    "\n",
    "def merge_features(strategy_returns_df, ticker_features_df):\n",
    "    strategy_daily = strategy_returns_df.resample('D').ffill()\n",
    "    ticker_daily = ticker_features_df.resample('D').ffill()\n",
    "\n",
    "    merged_df = pd.merge(strategy_daily, ticker_daily, left_index=True, right_index=True, how='inner')\n",
    "\n",
    "    # remove features that have too many nans\n",
    "    nan_fraction = merged_df.isna().mean()\n",
    "    cols_to_drop = nan_fraction[nan_fraction > 0.3].index.tolist()\n",
    "    if cols_to_drop:\n",
    "        merged_df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "    merged_df.fillna(method='ffill', inplace=True)\n",
    "    merged_df.fillna(method='bfill', inplace=True)\n",
    "    merged_df.dropna(inplace=True)\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "def preprocess_data(df, target_column='Sharpe_Ratio_30', correlation_threshold=0.9):\n",
    "    X = df.drop(columns=[target_column], errors='ignore')\n",
    "    y = df[target_column]\n",
    "\n",
    "    # scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled = pd.DataFrame(X_scaled, index=X.index, columns=X.columns)\n",
    "\n",
    "    # remove correlated features\n",
    "    corr_matrix = X_scaled.corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > correlation_threshold)]\n",
    "    X_scaled_reduced = X_scaled.drop(columns=to_drop)\n",
    "\n",
    "    print(f\"Removed {to_drop}\")\n",
    "\n",
    "    return X_scaled_reduced, y, scaler\n",
    "\n",
    "def split_data(X, y, test_size=0.2):\n",
    "    split_index = int(len(X) * (1 - test_size))\n",
    "    X_train = X.iloc[:split_index]\n",
    "    X_test = X.iloc[split_index:]\n",
    "    y_train = y.iloc[:split_index]\n",
    "    y_test = y.iloc[split_index:]\n",
    "    \n",
    "    print(f\"Train: {X_train.shape[0]} rows\")\n",
    "    print(f\"Test: {X_test.shape[0]} rows\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3d078ff1-49ce-40dd-8b80-b539def7ccde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_112910/2733699081.py:27: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df.fillna(method='ffill', inplace=True)\n",
      "/tmp/ipykernel_112910/2733699081.py:28: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df.fillna(method='bfill', inplace=True)\n",
      "/tmp/ipykernel_112910/2733699081.py:27: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df.fillna(method='ffill', inplace=True)\n",
      "/tmp/ipykernel_112910/2733699081.py:28: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df.fillna(method='bfill', inplace=True)\n",
      "/tmp/ipykernel_112910/2733699081.py:27: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df.fillna(method='ffill', inplace=True)\n",
      "/tmp/ipykernel_112910/2733699081.py:28: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df.fillna(method='bfill', inplace=True)\n",
      "/tmp/ipykernel_112910/2733699081.py:27: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df.fillna(method='ffill', inplace=True)\n",
      "/tmp/ipykernel_112910/2733699081.py:28: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df.fillna(method='bfill', inplace=True)\n",
      "/tmp/ipykernel_112910/2733699081.py:27: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df.fillna(method='ffill', inplace=True)\n",
      "/tmp/ipykernel_112910/2733699081.py:28: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df.fillna(method='bfill', inplace=True)\n",
      "/tmp/ipykernel_112910/2733699081.py:27: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df.fillna(method='ffill', inplace=True)\n",
      "/tmp/ipykernel_112910/2733699081.py:28: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df.fillna(method='bfill', inplace=True)\n",
      "/tmp/ipykernel_112910/2733699081.py:27: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df.fillna(method='ffill', inplace=True)\n",
      "/tmp/ipykernel_112910/2733699081.py:28: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df.fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    " for ticker in tickers:\n",
    "        ticker_feature_file = f\"all_features_{ticker}.csv\"\n",
    "        ticker_feature_path = os.path.join(ticker_features_dir, ticker_feature_file)\n",
    "\n",
    "        if not os.path.isfile(ticker_feature_path):\n",
    "            print(f\"{ticker_feature_path} not found\")\n",
    "            continue\n",
    "\n",
    "        ticker_df = load_csv(ticker_feature_path)\n",
    "        if ticker_df is None:\n",
    "            continue\n",
    "\n",
    "        strategy_files = [f for f in os.listdir(returns_features_dir) if f.endswith(\".csv\")]\n",
    "\n",
    "        for strategy_file in strategy_files:\n",
    "            strategy_name = strategy_file.replace(\"_returns_features.csv\", \"\")\n",
    "            strategy_feature_path = os.path.join(returns_features_dir, strategy_file)\n",
    "\n",
    "            strategy_df = load_csv(strategy_feature_path)\n",
    "            if strategy_df is None:\n",
    "                continue\n",
    "\n",
    "            # merge features\n",
    "            merged_df = merge_features(strategy_df, ticker_df)\n",
    "\n",
    "            merged_feature_file = f\"merged_features_{strategy_name}.csv\"\n",
    "            merged_feature_path = os.path.join(merged_features_dir, merged_feature_file)\n",
    "            merged_df.to_csv(merged_feature_path)\n",
    "\n",
    "# load datasets for each strategy\n",
    "merged_files = [f for f in os.listdir(merged_features_dir) if f.startswith(\"merged_features_\") and f.endswith(\".csv\")]\n",
    "datasets = {}\n",
    "for merged_file in merged_files:\n",
    "    strategy_name = merged_file.replace(\"merged_features_\", \"\").replace(\".csv\", \"\")\n",
    "    merged_feature_path = os.path.join(merged_features_dir, merged_file)\n",
    "    df = load_csv(merged_feature_path)\n",
    "    if df is not None:\n",
    "        datasets[strategy_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f5facbf7-638a-4736-b16b-3cc61b93b7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X_train, y_train):\n",
    "    models = {}\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    models['Linear Regression'] = lr\n",
    "    \n",
    "    rf = RandomForestRegressor(n_estimators=100)\n",
    "    rf.fit(X_train, y_train)\n",
    "    models['Random Forest'] = rf\n",
    "    \n",
    "    return models\n",
    "\n",
    "def evaluate_models(models, X_test, y_test):\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        results[name] = {'MSE': mse, 'R²': r2}\n",
    "        print(f\"{name} - MSE: {mse:.4f}, R²: {r2:.4f}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0b7cc01f-684f-4f4a-9f05-cca254088d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_all_strategies(datasets, models_dir, evaluations_dir, target='Sharpe_Ratio_30'):\n",
    "    for strategy, df in datasets.items():\n",
    "        print(f\"\\n=== Processing Strategy: {strategy} ===\")\n",
    "        \n",
    "        if target not in df.columns:\n",
    "            continue\n",
    "        \n",
    "        X_scaled_reduced, y, scaler = preprocess_data(df, target_column=target)\n",
    "        X_train, X_test, y_train, y_test = split_data(X_scaled_reduced, y, test_size=0.2)\n",
    "        \n",
    "        models = train_models(X_train, y_train)\n",
    "        \n",
    "        results = evaluate_models(models, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e32723f6-67ce-419e-a91d-f5a2180dc418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Strategy: G44 ===\n",
      "Removed ['CVaR_95_10', 'Kurtosis_30', 'Realized_Volatility_10', 'Garman_Klass_Volatility_10', 'Max_Drawdown_Duration_10', 'Realized_Volatility_30', 'Parkinson_Volatility_30', 'Garman_Klass_Volatility_30', 'Max_Drawdown_Duration_30_y', 'MACD_Signal_10', 'MACD_30', 'MACD_Signal_30', 'MACD_Diff_30']\n",
      "Train: 659 rows\n",
      "Test: 165 rows\n",
      "Linear Regression - MSE: 1.8957, R²: 0.8028\n",
      "Random Forest - MSE: 1.2915, R²: 0.8656\n",
      "\n",
      "=== Processing Strategy: G43 ===\n",
      "Removed ['CVaR_95_10', 'CVaR_95_30', 'Realized_Volatility_10', 'Garman_Klass_Volatility_10', 'Max_Drawdown_Duration_10', 'Realized_Volatility_30', 'Parkinson_Volatility_30', 'Garman_Klass_Volatility_30', 'Max_Drawdown_Duration_30_y', 'MACD_Signal_10', 'RSI_10', 'MACD_30', 'MACD_Signal_30', 'MACD_Diff_30', 'RSI_30']\n",
      "Train: 316 rows\n",
      "Test: 79 rows\n",
      "Linear Regression - MSE: 3.9157, R²: 0.4833\n",
      "Random Forest - MSE: 0.1249, R²: 0.9835\n",
      "\n",
      "=== Processing Strategy: G59_V1 ===\n",
      "Removed ['CVaR_95_10', 'CVaR_95_30', 'Realized_Volatility_10', 'Garman_Klass_Volatility_10', 'Max_Drawdown_Duration_10', 'Realized_Volatility_30', 'Parkinson_Volatility_30', 'Garman_Klass_Volatility_30', 'Max_Drawdown_Duration_30_y', 'MACD_Signal_10', 'MACD_30', 'MACD_Signal_30', 'MACD_Diff_30']\n",
      "Train: 659 rows\n",
      "Test: 165 rows\n",
      "Linear Regression - MSE: 1.5481, R²: 0.5552\n",
      "Random Forest - MSE: 0.2066, R²: 0.9406\n",
      "\n",
      "=== Processing Strategy: G53_V1 ===\n",
      "Removed ['CVaR_95_10', 'Realized_Volatility_10', 'Garman_Klass_Volatility_10', 'Max_Drawdown_Duration_10', 'Realized_Volatility_30', 'Parkinson_Volatility_30', 'Garman_Klass_Volatility_30', 'Max_Drawdown_Duration_30_y', 'MACD_Signal_10', 'MACD_30', 'MACD_Signal_30', 'MACD_Diff_30']\n",
      "Train: 659 rows\n",
      "Test: 165 rows\n",
      "Linear Regression - MSE: 1.8673, R²: 0.4464\n",
      "Random Forest - MSE: 0.0295, R²: 0.9913\n",
      "\n",
      "=== Processing Strategy: G24 ===\n",
      "Removed ['Sharpe_Ratio_10', 'CVaR_95_10', 'Realized_Volatility_10', 'Garman_Klass_Volatility_10', 'Max_Drawdown_Duration_10', 'Realized_Volatility_30', 'Parkinson_Volatility_30', 'Garman_Klass_Volatility_30', 'Max_Drawdown_Duration_30_y', 'MACD_Signal_10', 'MACD_30', 'MACD_Signal_30', 'MACD_Diff_30']\n",
      "Train: 658 rows\n",
      "Test: 165 rows\n",
      "Linear Regression - MSE: 3.4669, R²: 0.7591\n",
      "Random Forest - MSE: 0.0930, R²: 0.9935\n",
      "\n",
      "=== Processing Strategy: G73 ===\n",
      "Removed ['CVaR_95_10', 'Realized_Volatility_10', 'Garman_Klass_Volatility_10', 'Max_Drawdown_Duration_10', 'Realized_Volatility_30', 'Parkinson_Volatility_30', 'Garman_Klass_Volatility_30', 'Max_Drawdown_Duration_30_y', 'MACD_Signal_10', 'MACD_30', 'MACD_Signal_30', 'MACD_Diff_30']\n",
      "Train: 659 rows\n",
      "Test: 165 rows\n",
      "Linear Regression - MSE: 6.3902, R²: -0.4986\n",
      "Random Forest - MSE: 0.1119, R²: 0.9738\n",
      "\n",
      "=== Processing Strategy: G33_V1 ===\n",
      "Removed ['CVaR_95_10', 'Kurtosis_30', 'Max_Drawdown_Duration_30_x', 'Realized_Volatility_10', 'Garman_Klass_Volatility_10', 'Max_Drawdown_Duration_10', 'Realized_Volatility_30', 'Parkinson_Volatility_30', 'Garman_Klass_Volatility_30', 'Max_Drawdown_Duration_30_y', 'MACD_Signal_10', 'MACD_30', 'MACD_Signal_30', 'MACD_Diff_30']\n",
      "Train: 659 rows\n",
      "Test: 165 rows\n",
      "Linear Regression - MSE: 3.9783, R²: 0.2999\n",
      "Random Forest - MSE: 0.3662, R²: 0.9356\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_all_strategies(datasets, models_dir, evaluations_dir, target='Sharpe_Ratio_30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd09f808-b3a5-4fcb-a243-c6e98578a5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
